PS C:\Users\Public\AplikasiAnalitik\drp-learning\p10> .\analyze.bat
=== MEMULAI ANALISIS 1 (Total Tonase per Jenis) ===
[1/6] Membuat direktori di container...
[2/6] Menyalin Hadoop Streaming JAR...
Successfully copied 131kB to namenode:/data/hadoop-streaming.jar
[3/6] Menyalin script Python dan Data Input...
Successfully copied 2.56kB to namenode:/data/mapper.py
Successfully copied 2.56kB to namenode:/data/reducer.py
Successfully copied 2.63MB to namenode:/data/input.csv
[4/6] Membersihkan HDFS...
rm: `/user/student/output_analisis1': No such file or directory
[5/6] Upload input ke HDFS...
2025-12-14 14:13:18,337 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
[6/6] Menjalankan MapReduce Job...
2025-12-14 14:13:23,281 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-12-14 14:13:23,389 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-12-14 14:13:23,390 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2025-12-14 14:13:23,403 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2025-12-14 14:13:23,665 INFO mapred.FileInputFormat: Total input files to process : 1
2025-12-14 14:13:23,914 INFO mapreduce.JobSubmitter: number of splits:1
2025-12-14 14:13:24,084 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1354956955_0001
2025-12-14 14:13:24,084 INFO mapreduce.JobSubmitter: Executing with tokens: []
2025-12-14 14:13:24,290 INFO mapred.LocalDistributedCacheManager: Creating symlink: /tmp/hadoop-root/mapred/local/job_local1354956955_0001_11685e3a-f550-458d-8d11-b16d7b4e87da/mapper.py <- //mapper.py
2025-12-14 14:13:24,315 INFO mapred.LocalDistributedCacheManager: Localized file:/data/mapper.py as file:/tmp/hadoop-root/mapred/local/job_local1354956955_0001_11685e3a-f550-458d-8d11-b16d7b4e87da/mapper.py
2025-12-14 14:13:24,332 INFO mapred.LocalDistributedCacheManager: Creating symlink: /tmp/hadoop-root/mapred/local/job_local1354956955_0001_5fe299b4-122d-4027-8da4-fe6c9de35448/reducer.py <- //reducer.py
2025-12-14 14:13:24,378 INFO mapred.LocalDistributedCacheManager: Localized file:/data/reducer.py as file:/tmp/hadoop-root/mapred/local/job_local1354956955_0001_5fe299b4-122d-4027-8da4-fe6c9de35448/reducer.py
2025-12-14 14:13:24,509 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
2025-12-14 14:13:24,518 INFO mapreduce.Job: Running job: job_local1354956955_0001
2025-12-14 14:13:24,530 INFO mapred.LocalJobRunner: OutputCommitter set in config null
2025-12-14 14:13:24,538 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
2025-12-14 14:13:24,544 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2025-12-14 14:13:24,545 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-12-14 14:13:24,609 INFO mapred.LocalJobRunner: Waiting for map tasks
2025-12-14 14:13:24,618 INFO mapred.LocalJobRunner: Starting task: attempt_local1354956955_0001_m_000000_0
2025-12-14 14:13:24,660 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2025-12-14 14:13:24,661 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-12-14 14:13:24,692 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2025-12-14 14:13:24,705 INFO mapred.MapTask: Processing split: hdfs://namenode:8020/user/student/input/input.csv:0+2629212
2025-12-14 14:13:24,731 INFO mapred.MapTask: numReduceTasks: 1
2025-12-14 14:13:24,830 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2025-12-14 14:13:24,830 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2025-12-14 14:13:24,830 INFO mapred.MapTask: soft limit at 83886080
2025-12-14 14:13:24,830 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2025-12-14 14:13:24,830 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2025-12-14 14:13:24,833 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2025-12-14 14:13:24,844 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, mapper.py]
2025-12-14 14:13:24,849 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
2025-12-14 14:13:24,849 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
2025-12-14 14:13:24,849 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2025-12-14 14:13:24,850 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2025-12-14 14:13:24,857 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2025-12-14 14:13:24,857 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2025-12-14 14:13:24,859 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
2025-12-14 14:13:24,859 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2025-12-14 14:13:24,862 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
2025-12-14 14:13:24,863 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2025-12-14 14:13:24,863 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
2025-12-14 14:13:24,864 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2025-12-14 14:13:24,911 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2025-12-14 14:13:25,056 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2025-12-14 14:13:25,057 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
2025-12-14 14:13:25,058 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
2025-12-14 14:13:25,064 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
2025-12-14 14:13:25,082 INFO streaming.PipeMapRed: Records R/W=3472/1
2025-12-14 14:13:25,118 INFO streaming.PipeMapRed: R/W/S=10000/4378/0 in:NA [rec/s] out:NA [rec/s]
2025-12-14 14:13:25,498 INFO streaming.PipeMapRed: MRErrorThread done
2025-12-14 14:13:25,499 INFO streaming.PipeMapRed: mapRedFinished
2025-12-14 14:13:25,502 INFO mapred.LocalJobRunner:
2025-12-14 14:13:25,502 INFO mapred.MapTask: Starting flush of map output
2025-12-14 14:13:25,502 INFO mapred.MapTask: Spilling map output
2025-12-14 14:13:25,502 INFO mapred.MapTask: bufstart = 0; bufend = 896249; bufvoid = 104857600
2025-12-14 14:13:25,502 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25942608(103770432); length = 271789/6553600
2025-12-14 14:13:25,541 INFO mapreduce.Job: Job job_local1354956955_0001 running in uber mode : false
2025-12-14 14:13:25,546 INFO mapreduce.Job:  map 0% reduce 0%
2025-12-14 14:13:25,783 INFO mapred.MapTask: Finished spill 0
2025-12-14 14:13:25,833 INFO mapred.Task: Task:attempt_local1354956955_0001_m_000000_0 is done. And is in the process of committing
2025-12-14 14:13:25,839 INFO mapred.LocalJobRunner: Records R/W=3472/1
2025-12-14 14:13:25,839 INFO mapred.Task: Task 'attempt_local1354956955_0001_m_000000_0' done.
2025-12-14 14:13:25,848 INFO mapred.Task: Final Counters for attempt_local1354956955_0001_m_000000_0: Counters: 23
        File System Counters
                FILE: Number of bytes read=130656
                FILE: Number of bytes written=1693949
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=2629212
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=5
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=1
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=67948
                Map output records=67948
                Map output bytes=896249
                Map output materialized bytes=1032151
                Input split bytes=101
                Combine input records=0
                Spilled Records=67948
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=12
                Total committed heap usage (bytes)=271581184
        File Input Format Counters
                Bytes Read=2629212
2025-12-14 14:13:25,848 INFO mapred.LocalJobRunner: Finishing task: attempt_local1354956955_0001_m_000000_0
2025-12-14 14:13:25,854 INFO mapred.LocalJobRunner: map task executor complete.
2025-12-14 14:13:25,860 INFO mapred.LocalJobRunner: Waiting for reduce tasks
2025-12-14 14:13:25,861 INFO mapred.LocalJobRunner: Starting task: attempt_local1354956955_0001_r_000000_0
2025-12-14 14:13:25,879 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2025-12-14 14:13:25,880 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-12-14 14:13:25,880 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2025-12-14 14:13:25,895 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@67fa00bc
2025-12-14 14:13:25,897 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2025-12-14 14:13:25,946 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=616195648, maxSingleShuffleLimit=154048912, mergeThreshold=406689152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2025-12-14 14:13:25,952 INFO reduce.EventFetcher: attempt_local1354956955_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2025-12-14 14:13:26,037 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1354956955_0001_m_000000_0 decomp: 1032147 len: 1032151 to MEMORY
2025-12-14 14:13:26,053 INFO reduce.InMemoryMapOutput: Read 1032147 bytes from map-output for attempt_local1354956955_0001_m_000000_0
2025-12-14 14:13:26,060 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1032147, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1032147
2025-12-14 14:13:26,062 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
2025-12-14 14:13:26,063 INFO mapred.LocalJobRunner: 1 / 1 copied.
2025-12-14 14:13:26,064 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2025-12-14 14:13:26,093 INFO mapred.Merger: Merging 1 sorted segments
2025-12-14 14:13:26,093 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1032139 bytes
2025-12-14 14:13:26,189 INFO reduce.MergeManagerImpl: Merged 1 segments, 1032147 bytes to disk to satisfy reduce memory limit
2025-12-14 14:13:26,190 INFO reduce.MergeManagerImpl: Merging 1 files, 1032151 bytes from disk
2025-12-14 14:13:26,191 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2025-12-14 14:13:26,191 INFO mapred.Merger: Merging 1 sorted segments
2025-12-14 14:13:26,192 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1032139 bytes
2025-12-14 14:13:26,192 INFO mapred.LocalJobRunner: 1 / 1 copied.
2025-12-14 14:13:26,208 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, reducer.py]
2025-12-14 14:13:26,210 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2025-12-14 14:13:26,211 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2025-12-14 14:13:26,275 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2025-12-14 14:13:26,275 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
2025-12-14 14:13:26,276 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
2025-12-14 14:13:26,282 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
2025-12-14 14:13:26,302 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]
2025-12-14 14:13:26,417 INFO streaming.PipeMapRed: MRErrorThread done
2025-12-14 14:13:26,420 INFO streaming.PipeMapRed: Records R/W=67948/1
2025-12-14 14:13:26,423 INFO streaming.PipeMapRed: mapRedFinished
2025-12-14 14:13:26,450 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2025-12-14 14:13:26,549 INFO mapreduce.Job:  map 100% reduce 0%
2025-12-14 14:13:26,654 INFO mapred.Task: Task:attempt_local1354956955_0001_r_000000_0 is done. And is in the process of committing
2025-12-14 14:13:26,657 INFO mapred.LocalJobRunner: 1 / 1 copied.
2025-12-14 14:13:26,657 INFO mapred.Task: Task attempt_local1354956955_0001_r_000000_0 is allowed to commit now
2025-12-14 14:13:26,689 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1354956955_0001_r_000000_0' to hdfs://namenode:8020/user/student/output_analisis1
2025-12-14 14:13:26,690 INFO mapred.LocalJobRunner: Records R/W=67948/1 > reduce
2025-12-14 14:13:26,691 INFO mapred.Task: Task 'attempt_local1354956955_0001_r_000000_0' done.
2025-12-14 14:13:26,691 INFO mapred.Task: Final Counters for attempt_local1354956955_0001_r_000000_0: Counters: 30
        File System Counters
                FILE: Number of bytes read=2194990
                FILE: Number of bytes written=2726100
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=2629212
                HDFS: Number of bytes written=88
                HDFS: Number of read operations=10
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=3
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Combine input records=0
                Combine output records=0
                Reduce input groups=5
                Reduce shuffle bytes=1032151
                Reduce input records=67948
                Reduce output records=5
                Spilled Records=67948
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=271581184
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Output Format Counters
                Bytes Written=88
2025-12-14 14:13:26,691 INFO mapred.LocalJobRunner: Finishing task: attempt_local1354956955_0001_r_000000_0
2025-12-14 14:13:26,692 INFO mapred.LocalJobRunner: reduce task executor complete.
2025-12-14 14:13:27,549 INFO mapreduce.Job:  map 100% reduce 100%
2025-12-14 14:13:27,550 INFO mapreduce.Job: Job job_local1354956955_0001 completed successfully
2025-12-14 14:13:27,559 INFO mapreduce.Job: Counters: 36
        File System Counters
                FILE: Number of bytes read=2325646
                FILE: Number of bytes written=4420049
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=5258424
                HDFS: Number of bytes written=88
                HDFS: Number of read operations=15
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=4
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=67948
                Map output records=67948
                Map output bytes=896249
                Map output materialized bytes=1032151
                Input split bytes=101
                Combine input records=0
                Combine output records=0
                Reduce input groups=5
                Reduce shuffle bytes=1032151
                Reduce input records=67948
                Reduce output records=5
                Spilled Records=135896
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=12
                Total committed heap usage (bytes)=543162368
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_LENGTH=0
                WRONG_LENGTH=0
                WRONG_LENGTH=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=2629212
        File Output Format Counters
                Bytes Written=88
2025-12-14 14:13:27,559 INFO streaming.StreamJob: Output directory: /user/student/output_analisis1

=== HASIL ANALISIS 1 (Total Tonase per Jenis) ===
2025-12-14 14:13:29,547 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false      
Kargo   155397150
Penumpang       156142323
Ro-Ro   155581466
Tanker  155651696
Tongkang        157962654

Selesai.
Press any key to continue . . .
PS C:\Users\Public\AplikasiAnalitik\drp-learning\p10>